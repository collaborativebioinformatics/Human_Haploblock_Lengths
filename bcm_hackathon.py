# -*- coding: utf-8 -*-
"""BCM_hackathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hF0HRvtzFnveGvTtaTTKPcEh0CfwqC8H
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# set -euo pipefail
# 
# # Install bcftools/tabix
# apt-get -y update
# apt-get -y install -qq bcftools tabix
# 
# # GIAB Ashkenazim trio base path
# BASE="https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio"
# 
# # Download child (HG002), father (HG003), mother (HG004)
# wget -c $BASE/HG002_NA24385_son/NISTv4.2.1/GRCh38/HG002_GRCh38_1_22_v4.2.1_benchmark.vcf.gz
# wget -c $BASE/HG002_NA24385_son/NISTv4.2.1/GRCh38/HG002_GRCh38_1_22_v4.2.1_benchmark.vcf.gz.tbi
# 
# wget -c $BASE/HG003_NA24149_father/NISTv4.2.1/GRCh38/HG003_GRCh38_1_22_v4.2.1_benchmark.vcf.gz
# wget -c $BASE/HG003_NA24149_father/NISTv4.2.1/GRCh38/HG003_GRCh38_1_22_v4.2.1_benchmark.vcf.gz.tbi
# 
# wget -c $BASE/HG004_NA24143_mother/NISTv4.2.1/GRCh38/HG004_GRCh38_1_22_v4.2.1_benchmark.vcf.gz
# wget -c $BASE/HG004_NA24143_mother/NISTv4.2.1/GRCh38/HG004_GRCh38_1_22_v4.2.1_benchmark.vcf.gz.tbi
# 
# # Extract 70–80 Mb region of chr6
# REGION="chr6:70000000-80000000"
# for S in HG002 HG003 HG004; do
#   bcftools view -r $REGION -v snps -m2 -M2 -f PASS -Oz \
#     ${S}_GRCh38_1_22_v4.2.1_benchmark.vcf.gz > ${S}.chr6_70_80Mb.vcf.gz
#   tabix -p vcf ${S}.chr6_70_80Mb.vcf.gz
# done
# 
# # Merge trio into one multi-sample VCF
# bcftools merge -Oz -o trio.chr6_70_80Mb.vcf.gz \
#   HG002.chr6_70_80Mb.vcf.gz HG003.chr6_70_80Mb.vcf.gz HG004.chr6_70_80Mb.vcf.gz
# tabix -p vcf trio.chr6_70_80Mb.vcf.gz
# 
# # Export genotypes into table
# bcftools query -r $REGION -f '%POS\t[%GT\t]\n' trio.chr6_70_80Mb.vcf.gz > trio_region_genotypes.tsv
#

import pandas as pd, matplotlib.pyplot as plt, numpy as np

# Load the genotype table (POS + 3 samples)
df = pd.read_csv("trio_region_genotypes.tsv", sep="\t", header=None, usecols=[0,1,2,3])
df.columns = ["POS","HG002","HG003","HG004"]
df["POS"] = pd.to_numeric(df["POS"], errors="coerce")
df = df.dropna(subset=["POS"])

print("Total variants in region:", len(df))

# Keep heterozygous child (phased or unphased)
df = df[df["HG002"].isin(["0|1","1|0","0/1","1/0"])].reset_index(drop=True)
print("Informative child hets:", len(df))

def infer_labels(row):
    child = row["HG002"].replace("/","|").split("|")
    dad   = set(row["HG003"].replace("/","|").split("|"))
    mom   = set(row["HG004"].replace("/","|").split("|"))
    h1,h2 = child
    if len(dad)==1 and len(mom)==1 and list(dad)[0]!=list(mom)[0]:
        pf, pm = list(dad)[0], list(mom)[0]
        return ("P" if h1==pf else "M", "P" if h2==pf else "M")
    if len(dad)==1:
        pf = list(dad)[0]
        return ("P" if h1==pf else "M", "P" if h2==pf else "M")
    if len(mom)==1:
        pm = list(mom)[0]
        return ("M" if h1==pm else "P", "M" if h2==pm else "P")
    return ("?","?")

hap1, hap2 = [], []
for _,row in df.iterrows():
    h1,h2 = infer_labels(row)
    hap1.append(h1); hap2.append(h2)

df["hap1"], df["hap2"] = hap1, hap2

# ---- Block detection
def to_blocks(pos, labs):
    out=[]; cur=None; start=None
    for p,l in zip(pos,labs):
        if l=="?":
            if cur: out.append((cur,start,prev))
            cur=None; start=None
        elif cur is None: cur=l; start=p
        elif l!=cur:
            out.append((cur,start,prev))
            cur=l; start=p
        prev=p
    if cur: out.append((cur,start,pos.iloc[-1]))
    return out

blocks_h1 = to_blocks(df["POS"], df["hap1"])
blocks_h2 = to_blocks(df["POS"], df["hap2"])

print("Blocks hap1:", len(blocks_h1))
print("Blocks hap2:", len(blocks_h2))

# ---- Recombination breakpoints
def recomb_stats(blocks, hapname):
    out=[]
    for i in range(1,len(blocks)):
        prev, curr = blocks[i-1], blocks[i]
        if prev[0] in ["P","M"] and curr[0] in ["P","M"] and prev[0]!=curr[0]:
            out.append({
                "haplotype": hapname,
                "recomb_at_bp": int(curr[1]),
                "from": prev[0],
                "to": curr[0],
                "prev_block_size": int(prev[2])-int(prev[1]),
                "next_block_size": int(curr[2])-int(curr[1])
            })
    return pd.DataFrame(out)

recomb_table = pd.concat([
    recomb_stats(blocks_h1,"HG002_hap1"),
    recomb_stats(blocks_h2,"HG002_hap2")
], ignore_index=True)

print("\nRecombination events detected:")
print(recomb_table)

recomb_table.to_csv("HG002_recombination_sites_chr6_70_80Mb.csv", index=False)

plt.figure(figsize=(14,3))
for lab,s,e in blocks_h1:
    plt.plot([s,e],[1,1],lw=8,color="green" if lab=="P" else "purple")
for lab,s,e in blocks_h2:
    plt.plot([s,e],[0,0],lw=8,color="green" if lab=="P" else "purple")
plt.ylim(-1,2)
plt.yticks([0,1],["HG002 hap2","HG002 hap1"])
plt.xlabel("chr6 position (bp)")
plt.title("HG002 haploblot chr6:70–80 Mb (green=Paternal, purple=Maternal)")
plt.tight_layout()
plt.savefig("haploblot_chr6_70_80Mb.png",dpi=200)
plt.show()

from google.colab import files
files.download("HG002_recombination_sites_chr6_70_80Mb.csv")
files.download("haploblot_chr6_70_80Mb.png")

import numpy as np

# --- Summaries ---
stats = {
    "total_variants": len(df),
    "informative_child_hets": len(df[df["HG002"].isin(["0|1","1|0","0/1","1/0"])]),
    "hap1_blocks": len(blocks_h1),
    "hap2_blocks": len(blocks_h2),
    "hap1_recombinations": (df["hap1"] != df["hap1"].shift()).sum() - 1,
    "hap2_recombinations": (df["hap2"] != df["hap2"].shift()).sum() - 1,
    "hap1_paternal_fraction": round((df["hap1"].value_counts().get("P",0) / len(df))*100,2),
    "hap1_maternal_fraction": round((df["hap1"].value_counts().get("M",0) / len(df))*100,2),
    "hap2_paternal_fraction": round((df["hap2"].value_counts().get("P",0) / len(df))*100,2),
    "hap2_maternal_fraction": round((df["hap2"].value_counts().get("M",0) / len(df))*100,2),
}

print("\n=== Summary Statistics (chr6:70–80Mb) ===")
for k,v in stats.items():
    print(f"{k}: {v}")

import seaborn as sns

block_sizes = [e-s for lab,s,e in blocks_h1+blocks_h2 if lab in ["P","M"]]
block_labels = [lab for lab,s,e in blocks_h1+blocks_h2 if lab in ["P","M"]]

plt.figure(figsize=(6,4))
sns.histplot(block_sizes, bins=30, kde=False)
plt.xlabel("Block size (bp)")
plt.ylabel("Count")
plt.title("Distribution of haplotype block sizes (HG002)")
plt.show()

print("Number of blocks:", len(blocks_h1+blocks_h2))
print("Block sizes:", [e-s for lab,s,e in blocks_h1+blocks_h2 if lab in ["P","M"]][:20])

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

block_sizes = [e-s for lab,s,e in blocks_h1+blocks_h2 if lab in ["P","M"]]

if len(block_sizes) == 0:
    print("⚠️ No paternal/maternal blocks to plot")
else:
    min_size, max_size = np.min(block_sizes), np.max(block_sizes)

    plt.figure(figsize=(10,5))
    sns.histplot(block_sizes, bins=30, color="steelblue", edgecolor="black")
    plt.xscale("log")
    plt.xlabel("Block size (bp, log10 scale)")
    plt.ylabel("Number of blocks")
    plt.title("Distribution of haplotype block sizes (HG002, chr6:70–80 Mb)")

    ylim = plt.ylim()
    plt.axvline(min_size, color="red", linestyle="--", label=f"Smallest: {min_size:,} bp")
    plt.axvline(max_size, color="green", linestyle="--", label=f"Largest: {max_size:,} bp")

    plt.text(min_size, ylim[1]*0.8, f"{min_size:,} bp", color="red", rotation=90,
             va="bottom", ha="right")
    plt.text(max_size, ylim[1]*0.8, f"{max_size:,} bp", color="green", rotation=90,
             va="bottom", ha="left")

    plt.legend()
    plt.show()

import numpy as np, pandas as pd, matplotlib.pyplot as plt

# ---- Build a clean block table from your existing blocks_h1/blocks_h2 ----
def blocks_to_rows(blocks, hapname):
    rows = []
    for lab, s, e in blocks:
        if lab in ("P","M"):
            s, e = int(s), int(e)
            if e > s:
                rows.append({
                    "haplotype": hapname,
                    "parent": lab,            # P or M
                    "start": s,
                    "end": e,
                    "length_bp": e - s
                })
    return rows

block_rows = []
block_rows += blocks_to_rows(blocks_h1, "hap1")
block_rows += blocks_to_rows(blocks_h2, "hap2")
bt = pd.DataFrame(block_rows)

if bt.empty:
    print("⚠️ No paternal/maternal blocks to summarize. "
          "This means all labels were '?' in this window or there were no callable blocks.")
else:
    # Sort so we can access min/max
    bt = bt.sort_values("length_bp", ascending=False).reset_index(drop=True)

    # Largest & smallest
    max_row = bt.iloc[0]
    min_row = bt.iloc[-1]

    print(f"Largest block: {max_row['length_bp']:,} bp  "
          f"(chr6:{max_row['start']:,}-{max_row['end']:,}, {max_row['haplotype']} {max_row['parent']})")
    print(f"Smallest block: {min_row['length_bp']:,} bp  "
          f"(chr6:{min_row['start']:,}-{min_row['end']:,}, {min_row['haplotype']} {min_row['parent']})")

    # ---- Histogram (log-scaled x) ----
    sizes = bt["length_bp"].to_numpy()
    # Make log-spaced bins so the histogram behaves on wide ranges
    bins = np.logspace(np.log10(max(1, sizes.min())), np.log10(sizes.max()), 30)

    plt.figure(figsize=(11,5))
    plt.hist(sizes, bins=bins)
    plt.xscale("log")
    plt.xlabel("Block size (bp, log10 scale)")
    plt.ylabel("Number of blocks")
    plt.title("HG002 haplotype block sizes (chr6:70–80 Mb)")

    # Vertical lines + annotations
    ymin, ymax = plt.ylim()
    plt.axvline(min_row["length_bp"], color="red", linestyle="--")
    plt.axvline(max_row["length_bp"], color="green", linestyle="--")
    plt.text(min_row["length_bp"], ymax*0.8, f"{int(min_row['length_bp']):,} bp",
             color="red", rotation=90, va="bottom", ha="right")
    plt.text(max_row["length_bp"], ymax*0.8, f"{int(max_row['length_bp']):,} bp",
             color="green", rotation=90, va="bottom", ha="left")

    plt.tight_layout()
    plt.savefig("block_size_hist.png", dpi=200)
    plt.show()

    # Save a full table you can inspect/sort later
    bt.to_csv("HG002_block_table_chr6_70_80Mb.csv", index=False)
    print("Saved:")
    print(" - block_size_hist.png")
    print(" - HG002_block_table_chr6_70_80Mb.csv")

import numpy as np
import matplotlib.pyplot as plt

# Gather block sizes
block_sizes = [e-s for lab,s,e in blocks_h1+blocks_h2 if lab in ["P","M"]]

if len(block_sizes) == 0:
    print("⚠️ No blocks to plot in this region")
else:
    min_size, max_size = np.min(block_sizes), np.max(block_sizes)

    # Create log-spaced bins
    bins = np.logspace(np.log10(max(1, min_size)), np.log10(max_size), 30)
    counts, edges = np.histogram(block_sizes, bins=bins)

    # Plot histogram bars
    fig, ax = plt.subplots(figsize=(12,6))
    bars = ax.bar(edges[:-1], counts, width=np.diff(edges), align="edge",
                  edgecolor="black", color="skyblue", alpha=0.8)

    ax.set_xscale("log")
    ax.set_xlabel("Block size (bp, log10 scale)")
    ax.set_ylabel("Number of blocks")
    ax.set_title("HG002 haplotype block sizes (chr6:70–80 Mb)")

    # Print count numbers above bars
    for x, c, w in zip(edges[:-1], counts, np.diff(edges)):
        if c > 0:
            ax.text(x + w/2, c + 2, str(c),
                    ha="center", va="bottom", fontsize=8, rotation=90)

    # Highlight smallest/largest
    ax.axvline(min_size, color="red", linestyle="--", label=f"Smallest: {min_size:,} bp")
    ax.axvline(max_size, color="green", linestyle="--", label=f"Largest: {max_size:,} bp")

    ylim = ax.get_ylim()
    ax.text(min_size, ylim[1]*0.8, f"{min_size:,} bp", color="red", rotation=90,
            va="bottom", ha="right")
    ax.text(max_size, ylim[1]*0.8, f"{max_size:,} bp", color="green", rotation=90,
            va="bottom", ha="left")

    ax.legend()
    plt.show()

    # Print stats in console too
    print(f"Smallest block = {min_size:,} bp")
    print(f"Largest block  = {max_size:,} bp")

for hap in ["hap1","hap2"]:
    counts = df[hap].value_counts()
    total = counts.sum()
    paternal = counts.get("P",0)
    maternal = counts.get("M",0)
    print(f"{hap}: {paternal/total:.1%} paternal, {maternal/total:.1%} maternal")

window_size = 100000  # 100 kb
df["bin"] = (df["POS"] // window_size) * window_size
density = df.groupby("bin").size()

plt.figure(figsize=(10,3))
plt.bar(density.index, density.values, width=window_size, align="edge", color="steelblue")
plt.xlabel("chr6 position (bp)")
plt.ylabel("SNP count")
plt.title("Variant density in chr6:70–80 Mb (HG002)")
plt.show()

p_blocks = [e-s for lab,s,e in blocks_h1+blocks_h2 if lab=="P"]
m_blocks = [e-s for lab,s,e in blocks_h1+blocks_h2 if lab=="M"]

print("Avg paternal block size:", np.mean(p_blocks))
print("Avg maternal block size:", np.mean(m_blocks))

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# apt-get -y update
# apt-get -y install samtools
#

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# set -euo pipefail
# wget -q -O chr6.fa.gz https://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/chr6.fa.gz
# gunzip -f chr6.fa.gz
# samtools faidx chr6.fa
#

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# set -euo pipefail
# 
# REGION=chr6:70000000-80000000
# VCF=trio.chr6_70_80Mb.vcf.gz
# 
# # (A) HG002 consensus with IUPAC codes at heterozygous sites
# samtools faidx chr6.fa $REGION | \
#   bcftools consensus -s HG002 -H I -o HG002_consensus_chr6_70_80Mb.fa $VCF
# 
# # (B) HG002 haplotype-specific consensuses (requires phase where available)
# samtools faidx chr6.fa $REGION | \
#   bcftools consensus -s HG002 -H 1 -o HG002_hap1_chr6_70_80Mb.fa $VCF
# 
# samtools faidx chr6.fa $REGION | \
#   bcftools consensus -s HG002 -H 2 -o HG002_hap2_chr6_70_80Mb.fa $VCF
# 
# echo "Wrote: HG002_consensus_chr6_70_80Mb.fa, HG002_hap1_chr6_70_80Mb.fa, HG002_hap2_chr6_70_80Mb.fa"
#

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# grep -n "^>" -n HG002_consensus_chr6_70_80Mb.fa
# head -n 2 HG002_consensus_chr6_70_80Mb.fa
#

from google.colab import files
files.download("HG002_consensus_chr6_70_80Mb.fa")
files.download("HG002_hap1_chr6_70_80Mb.fa")
files.download("HG002_hap2_chr6_70_80Mb.fa")

!pip install bio
from Bio import SeqIO
import pandas as pd

files = ["HG002_consensus_chr6_70_80Mb.fa",
         "HG002_hap1_chr6_70_80Mb.fa",
         "HG002_hap2_chr6_70_80Mb.fa"]

stats = []
for f in files:
    for record in SeqIO.parse(f, "fasta"):
        seq = str(record.seq).upper()
        length = len(seq)
        gc = (seq.count("G")+seq.count("C"))/length*100
        n_count = seq.count("N")
        stats.append({
            "file": f,
            "id": record.id,
            "length": length,
            "GC%": round(gc,2),
            "N_bases": n_count
        })

df_stats = pd.DataFrame(stats)
print(df_stats)
df_stats.to_csv("consensus_stats.csv", index=False)

from Bio import SeqIO
hap1 = str(next(SeqIO.parse("HG002_hap1_chr6_70_80Mb.fa", "fasta")).seq)
hap2 = str(next(SeqIO.parse("HG002_hap2_chr6_70_80Mb.fa", "fasta")).seq)

diffs = [(i, hap1[i], hap2[i]) for i in range(len(hap1)) if hap1[i]!=hap2[i]]

print("Number of differences between hap1 and hap2:", len(diffs))
print("First 10 differences:", diffs[:10])

import matplotlib.pyplot as plt
pos = [d[0] for d in diffs]
plt.figure(figsize=(12,3))
plt.plot(pos, [1]*len(pos), '|', markersize=10, color="red")
plt.title("Positions where hap1 ≠ hap2 (HG002 chr6:70–80 Mb)")
plt.xlabel("Position (bp)")
plt.yticks([])
plt.show()

ref = str(next(SeqIO.parse("chr6.fa", "fasta")).seq[70000000:80000000])

cons = str(next(SeqIO.parse("HG002_consensus_chr6_70_80Mb.fa", "fasta")).seq)

mismatches = [(i+70000000, ref[i], cons[i]) for i in range(len(ref)) if ref[i]!=cons[i]]

print("Number of mismatches vs reference:", len(mismatches))
print("First 10 mismatches:", mismatches[:10])

pd.DataFrame(mismatches, columns=["pos","ref","cons"]).to_csv("HG002_vs_ref_mismatches.csv", index=False)